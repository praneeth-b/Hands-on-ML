{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # The code to download the mnist data original came from\n",
    "    # https://cntk.ai/pythondocs/CNTK_103A_MNIST_DataLoader.html\n",
    "    \n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import struct\n",
    "\n",
    "    try: \n",
    "        from urllib.request import urlretrieve \n",
    "    except ImportError: \n",
    "        from urllib import urlretrieve\n",
    "\n",
    "    def load_data(src, num_samples):\n",
    "        print(\"Downloading \" + src)\n",
    "        gzfname, h = urlretrieve(src, \"./delete.me\")\n",
    "        print(\"Done.\")\n",
    "        try:\n",
    "            with gzip.open(gzfname) as gz:\n",
    "                n = struct.unpack(\"I\", gz.read(4))\n",
    "                # Read magic number.\n",
    "                if n[0] != 0x3080000:\n",
    "                    raise Exception(\"Invalid file: unexpected magic number.\")\n",
    "                # Read number of entries.\n",
    "                n = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                if n != num_samples:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected {0} entries.\".format(num_samples)\n",
    "                    )\n",
    "                crow = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                ccol = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                if crow != 28 or ccol != 28:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected 28 rows/cols per image.\"\n",
    "                    )\n",
    "                # Read data.\n",
    "                res = np.frombuffer(\n",
    "                    gz.read(num_samples * crow * ccol), dtype=np.uint8\n",
    "                )\n",
    "        finally:\n",
    "            os.remove(gzfname)\n",
    "        return res.reshape((num_samples, crow, ccol)) / 256\n",
    "\n",
    "\n",
    "    def load_labels(src, num_samples):\n",
    "        print(\"Downloading \" + src)\n",
    "        gzfname, h = urlretrieve(src, \"./delete.me\")\n",
    "        print(\"Done.\")\n",
    "        try:\n",
    "            with gzip.open(gzfname) as gz:\n",
    "                n = struct.unpack(\"I\", gz.read(4))\n",
    "                # Read magic number.\n",
    "                if n[0] != 0x1080000:\n",
    "                    raise Exception(\"Invalid file: unexpected magic number.\")\n",
    "                # Read number of entries.\n",
    "                n = struct.unpack(\">I\", gz.read(4))\n",
    "                if n[0] != num_samples:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected {0} rows.\".format(num_samples)\n",
    "                    )\n",
    "                # Read labels.\n",
    "                res = np.frombuffer(gz.read(num_samples), dtype=np.uint8)\n",
    "        finally:\n",
    "            os.remove(gzfname)\n",
    "        return res.reshape((num_samples))\n",
    "\n",
    "\n",
    "    def try_download(data_source, label_source, num_samples):\n",
    "        data = load_data(data_source, num_samples)\n",
    "        labels = load_labels(label_source, num_samples)\n",
    "        return data, labels\n",
    "    \n",
    "    \n",
    "    # Not sure why, but yann lecun's website does no longer support \n",
    "    # simple downloader. (e.g. urlretrieve and wget fail, while curl work)\n",
    "    # Since not everyone has linux, use a mirror from uni server.\n",
    "    #     server = 'http://yann.lecun.com/exdb/mnist'\n",
    "    server = 'https://raw.githubusercontent.com/fgnt/mnist/master'\n",
    "    \n",
    "    # URLs for the train image and label data\n",
    "    url_train_image = f'{server}/train-images-idx3-ubyte.gz'\n",
    "    url_train_labels = f'{server}/train-labels-idx1-ubyte.gz'\n",
    "    num_train_samples = 60000\n",
    "\n",
    "    print(\"Downloading train data\")\n",
    "    train_features, train_labels = try_download(url_train_image, url_train_labels, num_train_samples)\n",
    "\n",
    "    # URLs for the test image and label data\n",
    "    url_test_image = f'{server}/t10k-images-idx3-ubyte.gz'\n",
    "    url_test_labels = f'{server}/t10k-labels-idx1-ubyte.gz'\n",
    "    num_test_samples = 10000\n",
    "\n",
    "    print(\"Downloading test data\")\n",
    "    test_features, test_labels = try_download(url_test_image, url_test_labels, num_test_samples)\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train data\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/train-images-idx3-ubyte.gz\n",
      "Done.\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/train-labels-idx1-ubyte.gz\n",
      "Done.\n",
      "Downloading test data\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/t10k-images-idx3-ubyte.gz\n",
      "Done.\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/t10k-labels-idx1-ubyte.gz\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels, test_features, test_labels = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "from tqdm import tqdm \n",
    "\n",
    "class ImgGenerator:\n",
    "    def __init__(self, orig_img, orig_label):\n",
    "        self.orig_img = orig_img\n",
    "        self.orig_label = orig_label\n",
    "        self.generated_imgs = []\n",
    "        self.labels = []\n",
    "        \n",
    "    def shift_image(self,img, x,y):\n",
    "        shifted_img = shift(img,[x,y])\n",
    "        return shifted_img\n",
    "    \n",
    "    \n",
    "    def generate_im(self, shift_x, shift_y):\n",
    "        pb = tqdm(total=len(self.orig_label))\n",
    "        for img, label in zip(self.orig_img, self.orig_label):\n",
    "            right_shift = self.shift_image(img, 0, shift_x)#.reshape(-1,28*28)\n",
    "            left_shift  = self.shift_image(img, 0, -shift_x)#.reshape(-1,28*28)\n",
    "            up_shift = self.shift_image(img, shift_y,0)#.reshape(-1,28*28)\n",
    "            down_shift = self.shift_image(img, -shift_y,0)#.reshape(-1,28*28)\n",
    "            self.generated_imgs.extend([img, right_shift, left_shift, up_shift, down_shift])\n",
    "            self.labels.extend([label]*5)\n",
    "            pb.update(1)\n",
    "        return self.generated_imgs, self.labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use the generated images to train the ANN\n",
    "# p = ImgGenerator(train_features, train_labels)\n",
    "# gen_img, gl = p.generate_im(2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_features[9])\n",
    "print('Label: {}'.format(test_labels[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_split(x, y, frac):\n",
    "    lx = len(x)\n",
    "    print(lx*frac)\n",
    "    p = np.random.permutation(len(x))\n",
    "    \n",
    "    return x[p[:int(lx*frac)]], y[p[:int(lx*frac)]], x[p[int(lx*frac):]], y[p[int(lx*frac):]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember:\n",
    "> With reshape you can stack all pixels in a big vector that can be used as NN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "train_features1 = train_features.reshape(-1, 28*28)\n",
    "test_features1 = test_features.reshape(-1, 28*28)\n",
    "print(train_features1.shape, train_labels.shape)\n",
    "#x_val, y_val, train_features1, train_labels = validation_split(train_features1, train_labels, 0.1)\n",
    "\n",
    "#gen_img = np.array(gen_img)\n",
    "#gen_img1 = gen_img.reshape(-1,28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, value, operation):\n",
    "        self.value = np.array(value)\n",
    "        self.operation = operation\n",
    "        \n",
    "    \n",
    "#     def backprop(self):\n",
    "#         # We define the backpropagation code later.\n",
    "#         return backprop(self)\n",
    "    \n",
    "class Parameter(Variable):\n",
    "    \"\"\"\n",
    "    This class should be used for Variables that are learnable.\n",
    "    You can later use this class to distinguish learnable variables\n",
    "    from other variables (`isinstance(variable, Parameter)`).\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        super().__init__(value, operation=None)\n",
    "        self.gradient = np.zeros_like(self.value)\n",
    "        \n",
    "class Input(Variable):\n",
    "    \"\"\"\n",
    "    This class should be used as wrapper for inputs that are not learnable.\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        super().__init__(value, operation=None)\n",
    "        \n",
    "\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.parameters = []\n",
    "    \n",
    "    def forward(self, X):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward(self,D):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def add_param(self, values):\n",
    "        param = Parameter(values)\n",
    "        self.parameters.append(param)\n",
    "        return param\n",
    "    \n",
    "    def update_parameters(self, optimizer):\n",
    "        for param in self.parameters:\n",
    "            optimizer.update(param)\n",
    "        \n",
    "\n",
    "class AffineLayer(Layer):\n",
    "    def __init__(self, in_units, out_units):\n",
    "        super().__init__()\n",
    "        small_value = 0.01\n",
    "        weight_vals = np.random.uniform(\n",
    "                    size=[in_units, out_units],\n",
    "                    low=-small_value,\n",
    "                    high=small_value\n",
    "                    )\n",
    "        self.W = self.add_param(weight_vals)\n",
    "        self.b = self.add_param(np.zeros(shape=out_units))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        def backward(D):\n",
    "            #print(self.__class__.__name__)\n",
    "            \n",
    "            self.W.gradient = self.W.gradient + X.T @ D  \n",
    "                                  ## todo to check for correctness (is += required)\n",
    "            self.b.gradient = self.b.gradient + np.sum(D,axis=0) \n",
    "           \n",
    "            return D @ self.W.value.T\n",
    "       \n",
    "       \n",
    "        return X @ self.W.value + self.b.value, backward\n",
    "    \n",
    "    \n",
    "class Sequential(Layer):\n",
    "    def __init__(self, *layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for layer in layers:\n",
    "            self.parameters.extend(layer.parameters) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        backprops = []\n",
    "        op = X\n",
    "        for layer in self.layers:\n",
    "            op, backprop = layer.forward(op)\n",
    "            backprops.append(backprop)\n",
    "\n",
    "        def backward(D):\n",
    "            for backprop in reversed(backprops):\n",
    "                D = backprop(D)\n",
    "            return D\n",
    "        return op , backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def forward(self, X):\n",
    "        mask = X > 0\n",
    "        return X * mask, lambda D: D * mask\n",
    "        \n",
    "    \n",
    "    \n",
    "class Sigmoid(Layer):\n",
    "    def forward(self, X):\n",
    "        op = 1/(1+np.exp(-X))\n",
    "        \n",
    "        def backward(D):\n",
    "            return D #* op * (1 - op)\n",
    "        \n",
    "        return op, backward\n",
    "    \n",
    "class SGDOptimizer():\n",
    "    def __init__(self, lr=0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, param):\n",
    "        param.value = param.value - self.lr * param.gradient \n",
    "        param.gradient.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(predictions, targets, epsilon=1e-11):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions. \n",
    "    Input: predictions (N, k) ndarray\n",
    "           targets (N, k) ndarray        \n",
    "    Returns: scalar\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets*np.log(predictions))/N\n",
    "    return ce , predictions - targets   #todo verify derivative of ce loss\n",
    "\n",
    "\n",
    "\n",
    "def mse_loss(Y_, Y):\n",
    "    diff = Y_ - Y.reshape(Y_.shape)\n",
    "    return np.square(diff).mean(), 2 * diff / len(diff)\n",
    "\n",
    "    \n",
    "\n",
    "def one_hot_encoder(x_label):\n",
    "    rows = x_label.shape[0]\n",
    "    oh_x = np.zeros((rows, 10))\n",
    "    for i in range(rows):\n",
    "        oh_x[i][x_label[i]] = 1\n",
    "    \n",
    "    return oh_x\n",
    "\n",
    "class Softmax(Layer):\n",
    "    def forward(self,X):\n",
    "        exps = np.exp(X - np.max(X))\n",
    "        def backward(D):\n",
    "            return D\n",
    "        return exps / np.sum(exps), backward\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt = one_hot_encoder(np.array([3,5]))\n",
    "# pred = np.random.rand(2,10)\n",
    "# l,d = cross_entropy(pred,tgt)\n",
    "# tgt*pred\n",
    "\n",
    "# print (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class DigitLearner():\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def fit_batch(self,X,Y):\n",
    "        Y_, backward = self.model.forward(X)\n",
    "          #softmax_crossentropy_with_logits\n",
    "        \n",
    "        L , D = self.loss(Y_, Y)           ## todo loss function derivative \n",
    "                                \n",
    "     \n",
    "        backward(D)\n",
    "        self.model.update_parameters(self.optimizer)\n",
    "        return L\n",
    "  \n",
    "    def fit(self, X, Y, epochs, bs):\n",
    "        losses = []\n",
    "        val_loss=[]\n",
    "        pbar = tqdm(total=epochs)\n",
    "        for epoch in range(epochs):\n",
    "            p = np.random.permutation(len(X))\n",
    "            L = 0\n",
    "            VL = 0\n",
    "            for i in range(0, len(X), bs):\n",
    "                X_batch = X[p[i:i + bs]]\n",
    "                Y_batch = Y[p[i:i + bs]]\n",
    "                L += self.fit_batch(X_batch, Y_batch)\n",
    "                \n",
    "  \n",
    "            losses.append(L)\n",
    "\n",
    "            pbar.update(1)\n",
    "        return losses\n",
    "    \n",
    "    def predict(self, xtest):\n",
    "        ypred, _ = self.model.forward(xtest)\n",
    "        return ypred.argmax(axis=-1)\n",
    "    \n",
    "    def accuracy(y_pred, y_test):\n",
    "        return np.sum(y_pred == y_test)/y_pred.shape[0]\n",
    "    \n",
    "    def dump_params(self,filename):\n",
    "        with open(filename, 'w') as fp:\n",
    "            json.dump([p.value.tolist() for p in self.model.parameters],fp)\n",
    "            print(\"weights written to file\")\n",
    "            \n",
    "    def load_params(self, filename):\n",
    "        with open(filename) as fp:\n",
    "            loaded_params = json.load(fp)\n",
    "        for p, p_value in zip(self.model.parameters, loaded_params):\n",
    "            p.value = p_value\n",
    "        print(\"Loaded given weights!!\")\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_parameters(loss, file):\n",
    "    variables = get_variables(J)\n",
    "    parameters = [\n",
    "        v \n",
    "        for v in variables\n",
    "        if isinstance(v, Parameter)\n",
    "    ]\n",
    "    with open(file, 'w') as fp:\n",
    "        json.dump([p.value.tolist() for p in parameters], fp)\n",
    "    print('Wrote the parameters')\n",
    "    print(parameters)\n",
    "    print('to', file)\n",
    "\n",
    "#dump_parameters(loss=J, file='parameters.json')\n",
    "\n",
    "\n",
    "def load_parameters(loss, file):\n",
    "    variables = get_variables(J)\n",
    "    parameters = [\n",
    "        v \n",
    "        for v in variables\n",
    "        if isinstance(v, Parameter)\n",
    "    ]\n",
    "    with open(file) as fp:\n",
    "        parameters_values = json.load(fp)\n",
    "    for p, p_value in zip(parameters, parameters_values):\n",
    "        print(p.value, p_value)\n",
    "        p.value[...] = p_value\n",
    "        \n",
    "    print('Loaded the parameters')\n",
    "    print(parameters)\n",
    "    print('from', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 1/35 [00:04<02:25,  4.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 2/35 [00:08<02:21,  4.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▊         | 3/35 [00:12<02:16,  4.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|█▏        | 4/35 [00:17<02:11,  4.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 5/35 [00:21<02:07,  4.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 6/35 [00:25<02:03,  4.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 7/35 [00:29<01:58,  4.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 8/35 [00:33<01:54,  4.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 9/35 [00:38<01:50,  4.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▊       | 10/35 [00:42<01:45,  4.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███▏      | 11/35 [00:46<01:41,  4.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 12/35 [00:50<01:37,  4.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 13/35 [00:55<01:33,  4.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 14/35 [00:59<01:29,  4.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 15/35 [01:05<01:34,  4.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 16/35 [01:09<01:26,  4.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▊     | 17/35 [01:13<01:20,  4.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████▏    | 18/35 [01:18<01:16,  4.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 19/35 [01:22<01:10,  4.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 20/35 [01:26<01:05,  4.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 21/35 [01:31<01:01,  4.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 22/35 [01:35<00:57,  4.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 23/35 [01:40<00:52,  4.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▊   | 24/35 [01:44<00:48,  4.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████▏  | 25/35 [01:48<00:43,  4.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 26/35 [01:53<00:39,  4.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 27/35 [01:57<00:34,  4.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 28/35 [02:01<00:30,  4.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 29/35 [02:05<00:25,  4.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 30/35 [02:10<00:21,  4.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████▊ | 31/35 [02:14<00:17,  4.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████▏| 32/35 [02:18<00:12,  4.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 33/35 [02:23<00:08,  4.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 34/35 [02:27<00:04,  4.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 35/35 [02:31<00:00,  4.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "hidden_neurons = 256\n",
    "lrate = 0.01\n",
    "epochs = 35\n",
    "batch = 32\n",
    "X = train_features1 #gen_img1\n",
    "y = train_labels\n",
    "Y = one_hot_encoder(train_labels)  # np.array(gl)  train_labels\n",
    "\n",
    "\n",
    "X_test = test_features1\n",
    "Y_test = test_labels\n",
    "\n",
    "test = DigitLearner(\n",
    "    Sequential(\n",
    "        AffineLayer(784, hidden_neurons), \n",
    "        ReLU(), \n",
    "        AffineLayer(hidden_neurons, hidden_neurons),\n",
    "        ReLU(),\n",
    "        AffineLayer(hidden_neurons, 10),\n",
    "        Sigmoid()        \n",
    "    ), \n",
    "    cross_entropy, \n",
    "    SGDOptimizer(lr=lrate)\n",
    ")\n",
    "\n",
    "losses = test.fit(X, Y, epochs=epochs, bs=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights written to file\n"
     ]
    }
   ],
   "source": [
    "# save weights to a json file\n",
    "test.dump_params(\"wt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new empty model here to load weights\n",
    "hidden_neurons = 256\n",
    "lrate = 0.01\n",
    "\n",
    "mt_model = DigitLearner(\n",
    "    Sequential(\n",
    "        AffineLayer(784, hidden_neurons), \n",
    "        ReLU(), \n",
    "        AffineLayer(hidden_neurons, hidden_neurons),\n",
    "        ReLU(),\n",
    "        AffineLayer(hidden_neurons, 10),\n",
    "        Sigmoid()        \n",
    "    ), \n",
    "    cross_entropy, \n",
    "    SGDOptimizer(lr=lrate)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded given weights!!\n"
     ]
    }
   ],
   "source": [
    "# load weights from a saved json file in a new model\n",
    "mt_model.load_params(\"wt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768\n"
     ]
    }
   ],
   "source": [
    "# use the new empty model with weights loaded from json to make prediction\n",
    "tacc = DigitLearner.accuracy(mt_model.predict(X_test), Y_test)\n",
    "print(tacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9855\n"
     ]
    }
   ],
   "source": [
    "#print(losses)\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.show()\n",
    "acc = DigitLearner.accuracy(test.predict(X_test), Y_test)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test.predict(X_test[:10])\n",
    "print(pred, Y_test[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
